{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\theano\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import telebot\n",
    "from config import TOKEN, LOG_FILE\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import scipy\n",
    "import pymystem3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from itertools import chain\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-cf3fb7203897>:44: SyntaxWarning: name 'graph' is assigned to before global declaration\n",
      "  global graph\n"
     ]
    }
   ],
   "source": [
    "class Backend(object):\n",
    "    \"\"\"\n",
    "    class contets few machine learning text handle methods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, w2v_path, json_path):\n",
    "        \"\"\"\n",
    "        initialize our class with model file, w2v file and json faq files \n",
    "        \"\"\"\n",
    "        self.model = load_model(model_path)\n",
    "        self.w2v = Word2Vec.load(w2v_path)\n",
    "        # self.faq = \n",
    "        self.tokenizer = RegexpTokenizer('[a-zA-Z0-9@]+')\n",
    "        self.stemmer = LancasterStemmer()\n",
    "        self.graph = tf.get_default_graph()\n",
    "        \n",
    "    def preproc_tweet(self, text):\n",
    "        \"\"\"\n",
    "        function preprocesing tweet to good format\n",
    "        \"\"\"\n",
    "        max_tweet_length = 20\n",
    "        vector_size = 512\n",
    "        \n",
    "        matrix = np.zeros((1, max_tweet_length, vector_size), dtype=K.floatx())\n",
    "\n",
    "        for t, token in enumerate(self.tokenizer.tokenize(text.lower())):\n",
    "            if t >= max_tweet_length:\n",
    "                break\n",
    "            try:    \n",
    "                matrix[0, t, :] = self.w2v[self.stemmer.stem(token)]\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        return matrix\n",
    "    \n",
    "    def predict_sentiment(self, matrix):\n",
    "        \"\"\"\n",
    "        fucntion returns sentiment\n",
    "        argeuments:\n",
    "            matrix - numpy array, matrix of w2v words ebeddings\n",
    "            model - keras deep learning model\n",
    "        \"\"\"\n",
    "        graph = self.graph\n",
    "        global graph\n",
    "        with graph.as_default():\n",
    "            sentiment = self.model.predict(matrix)[0][1]\n",
    "        \n",
    "        return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepr = bk.predict_sentiment(bk.preproc_tweet('What a lonely day! And it\\'s mine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot = telebot.TeleBot(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load some backend for bot\n",
    "bk = Backend('../lecture1/weights-improvement-09-0.81.hdf5', '../lecture1/test.wv','')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# Logging to file\n",
    "fh = logging.FileHandler(LOG_FILE)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "# Logging to console\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "@bot.message_handler(commands=['start', 'help'])\n",
    "def greetings(message):\n",
    "    try:\n",
    "        logger.info('Started chat # {}'.format(message.chat.id))\n",
    "        bot.reply_to(message, 'Приветики, {} {}! Меня зовут {} (если коротко, то Сэнди), я к твоим услугам.\\n'\n",
    "                    'Вот что я могу:\\n'\n",
    "                    '/start - Начинаю чат и пишу тебе все, что умею (каждый раз, чтобы не забыл)\\n'\n",
    "                    '/help - Печатаю помощь (да, чтобы не забыл ;))\\n'\n",
    "                    '/sentiment [message] - предсказываю с помощью хрустального шара положительную (1) или отрицательную (0) окраску твита (только по-аглийски)\\n'\n",
    "                    '/answer [message] - Отвечаю по моему справочнику FAQ (надеюсь, что это не что-то неприличное) на твое сообщение'.format(message.chat.first_name,\n",
    "                                                                        message.chat.last_name, bot.get_me().username))\n",
    "    except:\n",
    "        bot.send_message(message.chat.id, 'Извини, я ошиблась. С кем не бывает?!')\n",
    "        \n",
    "@bot.message_handler(commands=['sentiment'])\n",
    "def predict_sentiment(message):\n",
    "    try:\n",
    "        text = ' '.join(message.text.split(' ')[1:]) # some idiot bicycle to delete command from text\n",
    "        result = bk.predict_sentiment(bk.preproc_tweet(text))\n",
    "        bot.send_message(message.chat.id, result)\n",
    "        logger.info('Predicted sentiment {} for tweet {}'.format(result, text))\n",
    "    except:\n",
    "        bot.send_message(message.chat.id, 'Извини, я ошиблась. С кем не бывает?!')\n",
    "        \n",
    "@bot.message_handler(commands=['answer'])\n",
    "def answer(message):\n",
    "    bot.send_message(message.chat.id, 'Ответ мой: 42')\n",
    "    \n",
    "@bot.message_handler(content_types=['text'])\n",
    "def small_talk(message):\n",
    "    bot.send_message(message.chat.id, \"Я бы с тобой поговорила, да вот сказать нечего :(\\n Введи-ка лучше команду.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-03 13:25:35,663 - __main__ - INFO - Started chat # 74141678\n",
      "2017-12-03 13:27:08,034 - __main__ - INFO - Predicted sentiment 0.8989554047584534 for tweet We will rise again\n",
      "2017-12-03 13:27:24,596 - __main__ - INFO - Predicted sentiment 0.009651520289480686 for tweet I am so sick\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    bot.polling(none_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Enable logging\n",
    "\n",
    "\n",
    "    # @bot.message_handler(content_types=[\"text\"])\n",
    "    # def repeat_all_messages(message): # Название функции не играет никакой роли, в принципе\n",
    "    #     bot.send_message(message.chat.id, message.text)\n",
    "\n",
    "    @bot.message_handler(commands=['start', 'help'])\n",
    "    def greetings(message):\n",
    "        try:\n",
    "            bot.reply_to(message, 'Greetings, {} {}! My name is {}, at your service.\\n'\n",
    "                        'I currently support the following commands:\\n'\n",
    "                        '/start - begins our chat and prints this message\\n'\n",
    "                        '/help - prints this message\\n'\n",
    "                        '/sentiment [message] - predicts the sentiment of the message (only english)\\n\n",
    "                        /answer [message] - answers to user message'.format(message.chat.first_name,\n",
    "                                                                            message.chat.last_name, bot.get_me().username))\n",
    "        except:\n",
    "            \n",
    "    @bot.message_handler(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    bot.polling(none_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable logging\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# Logging to file\n",
    "fh = logging.FileHandler(LOG_FILE)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "# Logging to console\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "class Bot:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.updater = Updater(TOKEN)\n",
    "        self.dsp = self.updater.dispatcher\n",
    "        \n",
    "        self.text = 'TEXT'\n",
    "\n",
    "        # register handler functions which define how the bot reacts to events\n",
    "        self.dsp.add_handler(CommandHandler(\"start\", get_help))\n",
    "        self.dsp.add_handler(CommandHandler(\"help\", get_help))\n",
    "        self.dsp.add_handler(CommandHandler(\"sentiment\", get_sentiment, pass_chat_data = True))\n",
    "        self.dsp.add_handler(CommandHandler(\"answer\", get_answer))\n",
    "        self.dsp.add_handler(MessageHandler(Filters.text, echo))\n",
    "        self.dsp.add_error_handler(error)\n",
    "\n",
    "        logger.info('Im alive!')\n",
    "        \n",
    "#     def load_model(self, w2v, model):\n",
    "#         # load w2v and \n",
    "    \n",
    "#     def preproc_\n",
    "\n",
    "    def power_on(self):\n",
    "        # start the Bot\n",
    "        self.updater.start_polling()\n",
    "        self.updater.idle()\n",
    "\n",
    "# define command handlers. These usually take the two arguments: bot and\n",
    "# update. Error handlers also receive the raised TelegramError object in error.\n",
    "\n",
    "\n",
    "def echo(bot, update):\n",
    "    logger.info('echo recieved message: {}'.format(update.message.text))\n",
    "    bot.sendMessage(update.message.chat_id, text=update.message.text)\n",
    "\n",
    "\n",
    "def error(bot, update, error):\n",
    "    # all uncaught telegram-related exceptions will be rerouted here\n",
    "    logger.error('Update \"%s\" caused error \"%s\"' % (update, error))\n",
    "\n",
    "\n",
    "def get_help(bot, update):\n",
    "    logger.info('get_help recieved message: {}'.format(update.message.text))\n",
    "    help_msg = ('Greetings, {} {}! Name is {}, at your service.\\n'\n",
    "                'I currently support the following commands:\\n'\n",
    "                '/start - begins our chat and prints this message\\n'\n",
    "                '/help - prints this message\\n'\n",
    "                '/sentiment [message] - predicts the sentiment of the message').format(\n",
    "        update.message.from_user.first_name, update.message.from_user.last_name, bot.name)\n",
    "    bot.sendMessage(update.message.chat_id, text=help_msg)\n",
    "    \n",
    "# def load_model(bot, update, chat_data):\n",
    "    \n",
    "\n",
    "def get_sentiment(bot, update, chat_data):\n",
    "    logger.info('get_sentiment recieved message: {}'.format(update.message.text))\n",
    "    try:\n",
    "        # get message text without the command '/sentiment'\n",
    "        usr_msg = update.message.text.split(' ', maxsplit=1)[1]\n",
    "        msg_sentiment = 0.5\n",
    "        '''\n",
    "        Now determine the sentiment of usr_msg.\n",
    "        This should return a real number in [0,1].\n",
    "        Your code goes here.\n",
    "        '''\n",
    "        \n",
    "        msg_sentiment = bot.text\n",
    "        \n",
    "        bot.sendMessage(update.message.chat_id, text=msg_sentiment)\n",
    "    except IndexError:\n",
    "        bot.sendMessage(update.message.chat_id, text='Write your message after the command')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        \n",
    "def get_answer(bot, update):\n",
    "    logger.info('get_answer recieved message: {}'.format(update.message.text))\n",
    "    try:\n",
    "        # get message text without the command \n",
    "        usr_msg = update.message.text.split(' ', maxsplit=1)[1]\n",
    "        # your code goes here\n",
    "        '''\n",
    "        Now determine the sentiment of usr_msg.\n",
    "        This should return a real number in [0,1].\n",
    "        Your code goes here.\n",
    "        '''\n",
    "        bot.sendMessage(update.message.chat_id, text=answer)\n",
    "    except IndexError:\n",
    "        bot.sendMessage(update.message.chat_id, text='Write your message after the command')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "\n",
    "my_bot = Bot()\n",
    "my_bot.power_on()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
