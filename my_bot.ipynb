{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\theano\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import telebot\n",
    "from config import TOKEN, LOG_FILE\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import scipy\n",
    "import pymystem3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from itertools import chain\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ENGINE_4(object):\n",
    "    def __init__(self, kbase_path, w2v_model):\n",
    "        self.knowledge_base = json.load(open(kbase_path))\n",
    "        self.lemmatizer = pymystem3.Mystem()\n",
    "        self.w2v_model = w2v_model\n",
    "        \n",
    "        # contains correct output for each class\n",
    "        self.answers = np.array([t['answer'] for t in self.knowledge_base])\n",
    "        self.tfidfmodel = self.prepare_vectorizer()\n",
    "        self.idf = self.tfidfmodel.idf_\n",
    "        self.idf_dict = {key:value for key, value in zip(self.tfidfmodel.get_feature_names(), self.idf)} \n",
    "        \n",
    "        self.vectorized_kbase, self.class_indexes = self.vectorize_knowledge_base()\n",
    "        \n",
    "    def prepare_vectorizer(self):\n",
    "        \"\"\"\n",
    "        Fits TF-IDF vectorizer using all available text from self.knowledge_base\n",
    "        \n",
    "        Returns TF-IDF vectorizer object\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        vectorizer = None\n",
    "        all_texts = []\n",
    "        \n",
    "        for kn in self.knowledge_base:\n",
    "            all_texts.append(kn['answer'])\n",
    "            for par in kn['paraphrased_questions']:\n",
    "                all_texts.append(par)\n",
    "            all_texts.append(kn['question'])\n",
    "        \n",
    "        # all_texts = [' '.join(self.tokenize_and_lemmatize(text)) for text in tqdm(texts)]\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(max_df = 0.9, min_df = 2, tokenizer=self.tokenize_and_lemmatize).fit(all_texts)\n",
    "\n",
    "        return vectorizer\n",
    "    \n",
    "    def vectorize(self, data):\n",
    "        \"\"\"\n",
    "        Turns a list of N strings into their vector representation using self.w2v_model.\n",
    "        In the simplest case, averages the word vectors of all words in a sentence.\n",
    "        Returns a a matrix of shape [N, 300]\n",
    "        \"\"\"\n",
    "        vectorized = []\n",
    "        # your code goes here\n",
    "        \n",
    "        for text in data:\n",
    "            zero_vector = np.zeros(self.w2v_model.vector_size)\n",
    "            word_vectors = []\n",
    "            \n",
    "            for token in self.tokenize_and_lemmatize(text):\n",
    "                try:\n",
    "                    word_vectors.append(self.w2v_model[token]*self.idf_dict[token])\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "            \n",
    "            if len(word_vectors):\n",
    "                vectorized.append(np.mean(word_vectors, axis=0))\n",
    "            else:\n",
    "                vectorized.append(zero_vector)\n",
    "        \n",
    "        return np.array(vectorized)\n",
    "        \n",
    "    def vectorize_knowledge_base(self):\n",
    "        \"\"\"\n",
    "        Vectorizes all questions AND paraphrased questions using the vectorize function.\n",
    "        Builds a list containing class id (it's index in self.knowledge_base) for each vectorized question.\n",
    "        \n",
    "        Example: you vectorized 1 question and 5 paraphrases for that question\n",
    "        Then you should append the ID of the question to class_labels list 5+1=6 times.\n",
    "        \"\"\"\n",
    "        vectors = []\n",
    "        class_labels = []\n",
    "        \n",
    "        # your code goes here\n",
    "        for num, kn in enumerate(self.knowledge_base):\n",
    "            step_kn = [kn['question']] + kn['paraphrased_questions']\n",
    "            vectors.append(self.vectorize(step_kn))\n",
    "            for i in range(len(step_kn)):\n",
    "                class_labels.append(num)\n",
    "            \n",
    "        return np.vstack(vectors), np.array(class_labels)\n",
    "    \n",
    "    def compute_class_scores(self, similarities):\n",
    "        \"\"\"\n",
    "        Accepts an array of similarities of shape (self.class_indexes, )\n",
    "        Computes scores for classes.\n",
    "        Returns a dictionary of size (n_classes) that looks like\n",
    "        {\n",
    "            0: 0.3,\n",
    "            1: 0.1,\n",
    "            2: 0.0,\n",
    "            class_n_id: class_n_score\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        class_scores = dict(zip(range(len(self.answers)), [0]*len(self.answers)))\n",
    "        \n",
    "        for n,i in enumerate(self.class_indexes):\n",
    "            class_scores[i] += similarities[n]\n",
    "        \n",
    "        # your code goes here\n",
    "        return class_scores\n",
    "        \n",
    "    def tokenize_and_lemmatize(self, text):\n",
    "        analysis = self.lemmatizer.analyze(text.strip())\n",
    "        tokens = []\n",
    "        for an in analysis:\n",
    "            if 'analysis' in an:\n",
    "                try:\n",
    "                    tokens.append(an['analysis'][0]['lex'])\n",
    "                except IndexError:\n",
    "                    tokens.append(an['text'])\n",
    "        return tokens\n",
    "    \n",
    "    def get_top(self, query, top_k=3):\n",
    "        if isinstance(query, str):\n",
    "            query = [query]\n",
    "            \n",
    "        vectorized_query = self.vectorize(query)\n",
    "        css = cosine_similarity(vectorized_query, self.vectorized_kbase)[0]\n",
    "        scores = self.compute_class_scores(css)\n",
    "        \n",
    "        sorted_scores = sorted(scores.items(), key= lambda x: x[1])[::-1][:top_k]\n",
    "        top_classes = np.array([c[0] for c in sorted_scores])\n",
    "        top_answers = list(self.answers[top_classes])\n",
    "        return top_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-7597cd5a222f>:43: SyntaxWarning: name 'graph' is assigned to before global declaration\n",
      "  global graph\n"
     ]
    }
   ],
   "source": [
    "class Backend(object):\n",
    "    \"\"\"\n",
    "    class contets few machine learning text handle methods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, w2v_path):\n",
    "        \"\"\"\n",
    "        initialize our class with model file, w2v file and json faq files \n",
    "        \"\"\"\n",
    "        self.model = load_model(model_path)\n",
    "        self.w2v = Word2Vec.load(w2v_path)\n",
    "        self.tokenizer = RegexpTokenizer('[a-zA-Z0-9@]+')\n",
    "        self.stemmer = LancasterStemmer()\n",
    "        self.graph = tf.get_default_graph()\n",
    "        \n",
    "    def preproc_tweet(self, text):\n",
    "        \"\"\"\n",
    "        function preprocesing tweet to good format\n",
    "        \"\"\"\n",
    "        max_tweet_length = 20\n",
    "        vector_size = 512\n",
    "        \n",
    "        matrix = np.zeros((1, max_tweet_length, vector_size), dtype=K.floatx())\n",
    "\n",
    "        for t, token in enumerate(self.tokenizer.tokenize(text.lower())):\n",
    "            if t >= max_tweet_length:\n",
    "                break\n",
    "            try:    \n",
    "                matrix[0, t, :] = self.w2v[self.stemmer.stem(token)]\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        return matrix\n",
    "    \n",
    "    def predict_sentiment(self, matrix):\n",
    "        \"\"\"\n",
    "        fucntion returns sentiment\n",
    "        argeuments:\n",
    "            matrix - numpy array, matrix of w2v words ebeddings\n",
    "            model - keras deep learning model\n",
    "        \"\"\"\n",
    "        graph = self.graph\n",
    "        global graph\n",
    "        with graph.as_default():\n",
    "            sentiment = self.model.predict(matrix)[0][1]\n",
    "        \n",
    "        return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepr = bk.predict_sentiment(bk.preproc_tweet('What a lonely day! And it\\'s mine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot = telebot.TeleBot(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format('word_vectors.w2v')\n",
    "print('loaded w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded sentiment\n"
     ]
    }
   ],
   "source": [
    "# load some backend for bot\n",
    "bk = Backend('weights-improvement-09-0.81.hdf5', 'test.wv')\n",
    "print('loaded sentiment')\n",
    "engine = ENGINE_4('./result_faq1.json', w2v)\n",
    "print('starts engine')\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# Logging to file\n",
    "fh = logging.FileHandler(LOG_FILE)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "# Logging to console\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "@bot.message_handler(commands=['start', 'help'])\n",
    "def greetings(message):\n",
    "    try:\n",
    "        logger.info('Started chat # {}'.format(message.chat.id))\n",
    "        bot.reply_to(message, 'Приветики, {} {}! Меня зовут {} (если коротко, то Сэнди), я к твоим услугам.\\n'\n",
    "                    'Вот что я могу:\\n'\n",
    "                    '/start - Начинаю чат и пишу тебе все, что умею (каждый раз, чтобы не забыл)\\n'\n",
    "                    '/help - Печатаю помощь (да, чтобы не забыл ;))\\n'\n",
    "                    '/sentiment [message] - предсказываю с помощью хрустального шара положительную (1) или отрицательную (0) окраску твита (только по-аглийски)\\n'\n",
    "                    '/answer [message] - Отвечаю по моему справочнику FAQ (надеюсь, что это не что-то неприличное) на твое сообщение'.format(message.chat.first_name,\n",
    "                                                                        message.chat.last_name, bot.get_me().username))\n",
    "    except:\n",
    "        bot.send_message(message.chat.id, 'Извини, я ошиблась. С кем не бывает?!')\n",
    "        \n",
    "@bot.message_handler(commands=['sentiment'])\n",
    "def predict_sentiment(message):\n",
    "    try:\n",
    "        text = ' '.join(message.text.split(' ')[1:]) # some idiot bicycle to delete command from text\n",
    "        result = bk.predict_sentiment(bk.preproc_tweet(text))\n",
    "        bot.send_message(message.chat.id, result)\n",
    "        logger.info('Predicted sentiment {} for tweet {}'.format(result, text))\n",
    "    except:\n",
    "        bot.send_message(message.chat.id, 'Извини, я ошиблась. С кем не бывает?!')\n",
    "        \n",
    "@bot.message_handler(commands=['answer'])\n",
    "def answer(message):\n",
    "    text = ' '.join(message.text.split(' ')[1:])\n",
    "    answer = engine.get_top(text, top_k=1)\n",
    "    bot.send_message(message.chat.id, answer[0])\n",
    "    \n",
    "@bot.message_handler(content_types=['text'])\n",
    "def small_talk(message):\n",
    "    bot.send_message(message.chat.id, \"Я бы с тобой поговорила, да вот сказать нечего :(\\n Введи-ка лучше команду.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    bot.polling(none_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
